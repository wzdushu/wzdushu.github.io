<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>kubernetes on 丸子有记</title><link>/categories/kubernetes/</link><description>Recent content in kubernetes on 丸子有记</description><generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>wzdushu@gmail.com (wanzi)</managingEditor><webMaster>wzdushu@gmail.com (wanzi)</webMaster><copyright>丸子有记</copyright><lastBuildDate>Mon, 19 Aug 2024 10:10:42 +0800</lastBuildDate><atom:link href="/categories/kubernetes/index.xml" rel="self" type="application/rss+xml"/><item><title>Summary of CKA Examination Experience in 2024</title><link>/post/kubernetes-cka-2024/</link><pubDate>Mon, 19 Aug 2024 10:10:42 +0800</pubDate><author>wzdushu@gmail.com (wanzi)</author><guid>/post/kubernetes-cka-2024/</guid><description>I have wanted to take a cloud native &amp;amp; k8s related certificate for a long time. The sooner the better. I have been postponing it until this year due to work reasons. I have seen its price increase twice (it hurts a little bit to say this). Recently, I finally had time to spare a week to prepare for the exam. Since I have been using kubernetes in my work</description></item><item><title>Using Alibaba Cloud's open source solution to enable multiple people to use a single GPU</title><link>/post/kubernetes-aliyun-gpushare-deploy/</link><pubDate>Fri, 30 Jun 2023 18:10:42 +0800</pubDate><author>wzdushu@gmail.com (wanzi)</author><guid>/post/kubernetes-aliyun-gpushare-deploy/</guid><description>Recently, a new AI project was launched, which mainly provides AI online experiments for universities. The project also purchased a GPU server, but there is only one Nvidia Tesla T4 card, which needs to support multiple students to do experiments online at the same time. The online experiment system is currently running on Kubernetes, so it is necessary to consider GPU sharing in the k8s environment. Alibaba Cloud GPU card</description></item><item><title>Kind builds a lightweight kubernetes cluster</title><link>/post/kubernetes-kind-build-clusters/</link><pubDate>Thu, 13 Apr 2023 18:22:42 +0800</pubDate><author>wzdushu@gmail.com (wanzi)</author><guid>/post/kubernetes-kind-build-clusters/</guid><description>I was reviewing Golang recently and wrote a web application. After running it locally, I wanted to test it in a k8s cluster. Due to the machine configuration, it was still a bit difficult to build a complete k8s cluster. I remember that a friend said that k8s can also be run in docker, so I tried it. Today&amp;rsquo;s protagonist is kind, so what is kind? What can kind be</description></item><item><title>Solve nginx file upload restrictions and 504 gateway timeout under k8s</title><link>/post/kubernetes-nginx-ingress-504/</link><pubDate>Mon, 08 Nov 2021 17:22:42 +0800</pubDate><author>wzdushu@gmail.com (wanzi)</author><guid>/post/kubernetes-nginx-ingress-504/</guid><description>Recently, there are two problems that need to be solved when using k8s clusters for business. Here are some records: 1M limit for uploading files on the front-end page 504 timeout occurs when the front-end page sends a POST request to the back-end The main solution to the first problem: the default upload size of nginx is 1M, and the following content is added to the http, server, location area</description></item><item><title>Alibaba Cloud ACK supports both public and private SLB</title><link>/post/kubernetes-aliyun-ingress-slb-intranet/</link><pubDate>Thu, 21 Oct 2021 17:22:42 +0800</pubDate><author>wzdushu@gmail.com (wanzi)</author><guid>/post/kubernetes-aliyun-ingress-slb-intranet/</guid><description>1. Background There is an ACK cluster Successfully deployed Nginx ingress controller and bound to the public network SLB Note: The Kubernetes cluster created through the Alibaba Cloud Container Service Management Console will automatically deploy a set of Nginx Ingress Controllers during initialization, which is mounted on the public network SLB instance by default. 2. Configuration 1. Create an intranet LB Alibaba Cloud Console, create an intranet SLB and bind</description></item><item><title>Using Prometheusalert to build Prometheus alert message aggregation</title><link>/post/prometheus-prometheusalert-alertmanager/</link><pubDate>Sat, 18 Sep 2021 17:22:42 +0800</pubDate><author>wzdushu@gmail.com (wanzi)</author><guid>/post/prometheus-prometheusalert-alertmanager/</guid><description>Deploy prometheusalert Copy 1 2 3 4 git clone https://github.com/feiyu563/PrometheusAlert.git cd PrometheusAlert/example/helm/prometheusalert #Update config/app.conf to set login user information and configure database information helm install -n monitoring . Create an enterprise WeChat group robot After the enterprise WeChat group, click the enterprise WeChat group, right-click &amp;ldquo;Add group robot&amp;rdquo;, and create a group robot to get a robot webhook address, record the address for backup. Prometheus access configuration Configure alertmanager Since</description></item><item><title>Use Velero to configure kubernetes cluster backup strategy</title><link>/post/kubernetes-velero-etcd-backup/</link><pubDate>Sat, 11 Sep 2021 17:22:42 +0800</pubDate><author>wzdushu@gmail.com (wanzi)</author><guid>/post/kubernetes-velero-etcd-backup/</guid><description>Backup is something that every Internet company technician has to do, and of course we are no exception. Today I mainly formulate some of my own strategies for the production environment kubernetes cluster, and share them with you here. The purpose of my kubernetes backup here is mainly to prevent the following situations: Prevent accidental deletion of a namespace in the cluster Prevent accidental operation from causing an abnormality in</description></item><item><title>Alibaba Cloud Shared GPU Solution Test</title><link>/post/kubernetes-gpushare-aliyun/</link><pubDate>Tue, 31 Aug 2021 14:22:42 +0800</pubDate><author>wzdushu@gmail.com (wanzi)</author><guid>/post/kubernetes-gpushare-aliyun/</guid><description>1. Deploy GPU sharing plug-in in k8s Before deployment, you need to ensure that nvidia-driver and nvidia-docker are installed on the k8s node, and the default runtime of docker is set to nvidia Copy 1 2 3 4 5 6 7 8 9 10 # cat /etc/docker/daemon.json { &amp;#34;runtimes&amp;#34;: { &amp;#34;nvidia&amp;#34;: { &amp;#34;path&amp;#34;: &amp;#34;/usr/bin/nvidia-container-runtime&amp;#34;, &amp;#34;runtimeArgs&amp;#34;: [] } }, &amp;#34;default-runtime&amp;#34;: &amp;#34;nvidia&amp;#34;, } 1. Install gpushare-device-plugin in helm Copy 1 2 3</description></item><item><title>kubeadm deploys a highly available kubernetes cluster</title><link>/post/kubernetes-kubeadm-haproxy-keepalived-deploy/</link><pubDate>Sun, 15 Aug 2021 17:22:42 +0800</pubDate><author>wzdushu@gmail.com (wanzi)</author><guid>/post/kubernetes-kubeadm-haproxy-keepalived-deploy/</guid><description>In order to verify the private deployment later , the intranet environment needs to quickly build a k8s cluster. Because I usually use kubeasz and kubespray to handle large-scale clusters before, this time for small environment clusters, it will be more efficient to directly use kubeadm to deploy. The following records the kubeadm deployment process: Cluster nodes: Copy 1 2 3 4 192.168.1.206 sd-cluster-206 node 192.168.1.207 sd-cluster-207 master,etcd 192.168.1.208 sd-cluster-208</description></item><item><title>Adding users to a kubernetes cluster</title><link>/post/kubernetes-add-user/</link><pubDate>Tue, 31 Dec 2019 10:22:42 +0800</pubDate><author>wzdushu@gmail.com (wanzi)</author><guid>/post/kubernetes-add-user/</guid><description>Previously, we built a kubernetes cluster environment through ansible. The main requirement here is to add a user for daily management and limit it to the specified namespace. The following operation is performed: Users in kubernetes There are two types of users (User) in K8S - service accounts (ServiceAccount) and users in the ordinary sense (User). ServiceAccount is managed by K8S, while User is usually managed externally. K8S does not</description></item><item><title>Deploy traefik2.1 in kubernetes cluster</title><link>/post/kubernetes-traefik-v2/</link><pubDate>Tue, 17 Dec 2019 10:22:42 +0800</pubDate><author>wzdushu@gmail.com (wanzi)</author><guid>/post/kubernetes-traefik-v2/</guid><description>Architecture &amp;amp; Concepts Traefik 2.x has a big change compared to 1.7.x architecture. As shown in the architecture diagram above, the main function is to support TCP protocol and add the concept of Router. Here we use Traefik 2.1 deployed in the kubernetes cluster. Business access is requested to traefik Ingress through haproxy. The following are some concepts involved in the construction process: EntryPoints: Traefik&amp;rsquo;s network entry, defining the port</description></item><item><title>kubeasz deploys k8s cluster</title><link>/post/kubernetes-kubeasz-deploy-automation/</link><pubDate>Thu, 12 Dec 2019 10:22:42 +0800</pubDate><author>wzdushu@gmail.com (wanzi)</author><guid>/post/kubernetes-kubeasz-deploy-automation/</guid><description>Environment preparation Master node Copy 1 2 3 172.16.244.14 172.16.244.16 172.16.244.18 Node node Copy 1 2 172.16.244.25 172.16.244.27 Master node VIP address: 172.16.243.13 Deployment tool: Ansible/kubeasz Initialize the environment Install Ansible Copy 1 2 3 4 5 apt update apt-get install ansible expect git clone https://github.com/easzlab/kubeasz cd kubeasz cp * /etc/ansible/ Configure ansible for password-free login Copy 1 2 ssh-keygen -t rsa -b 2048 #Generate key ./tools/yc-ssh-key-copy.sh hosts root &amp;#39;rootpassword&amp;#39;</description></item></channel></rss>